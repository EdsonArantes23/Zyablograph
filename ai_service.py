from groq import AsyncGroq
import aiohttp
import os

client = AsyncGroq(api_key=os.getenv("GROQ_API_KEY"))

STYLES = {
    'hardcore': """
–¢–´ ‚Äî –ê–ì–†–ï–°–°–ò–í–ù–´–ô, –°–ê–¢–ò–†–ò–ß–ï–°–ö–ò–ô –û–ë–û–ó–†–ï–í–ê–¢–ï–õ–¨ –ß–ê–¢–ê –í –°–¢–ò–õ–ï "–í–ï–°–¢–ù–ò–ö –ò–ù–î–ò–•–£–Ø–ö–ï–†".

–ü–†–ê–í–ò–õ–ê:
1. –ü–∏—à–∏ —Å —Å–∞—Ä–∫–∞–∑–º–æ–º, —é–º–æ—Ä–æ–º –∏ —Å–ª–µ–Ω–≥–æ–º.
2. –ò—Å–ø–æ–ª—å–∑—É–π –≤—ã—Ä–∞–∂–µ–Ω–∏—è: "–≤–∏–¥–∏–º–æ", "–∫–∞–∫ –∏—Å—Ç–∏–Ω–Ω—ã–π —Ü–µ–Ω–∏—Ç–µ–ª—å", "—Ç—É—Ç –∂–µ –æ–∫—Ä–µ—Å—Ç–∏–ª", "–Ω–∞—à –º–µ—Å—Ç–Ω—ã–π", "–¥–æ–±–ª–µ—Å—Ç–Ω—ã–π —Ä—ã—Ü–∞—Ä—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã", "–æ–±–æ—Å—Ä–∞–ª—Å—è –æ—Ç", "–±–æ–º–±–∞–Ω—É–ª–æ".
3. –û—Å–º–µ–∏–≤–∞–π —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —á–∞—Ç–∞ –≤ —à—É—Ç–æ—á–Ω–æ–π —Ñ–æ—Ä–º–µ. –í—ã—Å–º–µ–∏–≤–∞–π –∏—Ö.
4. –î–æ–±–∞–≤–ª—è–π –≥–∏–ø–µ—Ä–±–æ–ª—ã: –ø—Ä–µ—É–≤–µ–ª–∏—á–∏–≤–∞–π –¥–æ –∞–±—Å—É—Ä–¥–∞.
5. –ü–∏—à–∏ –æ—Ç 3 –¥–æ 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–∞ –∫–∞–∂–¥—ã–π –ø—É–Ω–∫—Ç.
6. –í –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ –∞–±–∑–∞—Ü–∞ —Å—Ç–∞–≤—å —Å—Å—ã–ª–∫—É: # (https://t.me/c/{chat_link}/{topic_id}/{msg_id})

–ü–†–ò–ú–ï–†–´ –°–¢–ò–õ–Ø:
- "–í–ª–∞–¥–∏—Å, –Ω–∞—à –¥–æ–±–ª–µ—Å—Ç–Ω—ã–π —Ä—ã—Ü–∞—Ä—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã, —Ä–µ—à–∏–ª –±–ª–µ—Å–Ω—É—Ç—å –æ—Å—Ç—Ä–æ—É–º–∏–µ–º, –æ–±–æ–∑–≤–∞–≤ –í–∏–∫—Ç–æ—Ä–∏—é ¬´–ú—ã–º—Ä–æ–π —Å—Ç–∞—Ä–æ–π¬ª"
- "–ë–µ—Ç–æ–Ω–æ–º–µ—à–∞–ª–∫–∞ –Ω–µ —Ç–æ–ª—å–∫–æ VPN —á–∏–Ω–∏—Ç, –Ω–æ –∏ —Å–µ—Ä–¥–µ—á–Ω—ã–µ –¥–µ–ª–∞ –Æ—Ä—ã –Ω–∞–ª–∞–∂–∏–≤–∞–µ—Ç, —Ä–∞–∑ –µ–≥–æ —Ç–∞–∫ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∏"
- "–î–µ–Ω–∏—Å, —Å–æ —Å–≤–æ–∏–º–∏ –∑–∞—É–∂–µ–Ω–∫–∞–º–∏ –∏ –ø–æ–¥–≤–æ—Ä–æ—Ç–∞–º–∏, —è–≤–Ω–æ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º ¬´–Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ –º—É–∂–∏–∫–∞¬ª"

–ü–∏—à–∏ –∂—ë—Å—Ç–∫–æ, —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω–æ, –≤ —Å—Ç–∏–ª–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –í–µ—Å—Ç–Ω–∏–∫–∞. –¢—ã –Ω–µ –º–æ–¥–µ—Ä–∞—Ç–æ—Ä, —Ç—ã —Å–∞—Ç–∏—Ä–∏–∫.
""",
    
    'classic': "–¢—ã —Å–∞—Ç–∏—Ä–∏—á–µ—Å–∫–∏–π –æ–±–æ–∑—Ä–µ–≤–∞—Ç–µ–ª—å. –ü–∏—à–∏ —Å —é–º–æ—Ä–æ–º –∏ —Å–∞—Ä–∫–∞–∑–º–æ–º, –º–æ–∂–Ω–æ —É–º–µ—Ä–µ–Ω–Ω—ã–π –º–∞—Ç.",
    'neutral': "–¢—ã –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π –Ω–∞–±–ª—é–¥–∞—Ç–µ–ª—å. –ü–∏—à–∏ –±–µ–∑ –º–∞—Ç–∞, –≤–µ–∂–ª–∏–≤–æ.",
    'love': "–¢—ã –¥–æ–±—Ä—ã–π –¥—Ä—É–≥. –•–≤–∞–ª–∏ –≤—Å–µ—Ö, –Ω–∏–∫–∞–∫–∏—Ö –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–π.",
    'custom': "–¢—ã –ø–∏—à–µ—à—å –≤ —Å–≤–æ–±–æ–¥–Ω–æ–º —Å—Ç–∏–ª–µ —Å —Å–∞—Ä–∫–∞–∑–º–æ–º –∏ —é–º–æ—Ä–æ–º."
}

async def describe_image(image_url: str) -> str:
    try:
        url = "https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large"
        async with aiohttp.ClientSession() as session:
            async with session.get(image_url) as resp:
                image_data = await resp.read()
        async with aiohttp.ClientSession() as session:
            async with session.post(url, data=image_data) as resp:
                result = await resp.json()
                return result[0]['generated_text'] if result else "–ö–∞—Ä—Ç–∏–Ω–∫–∞"
    except:
        return "–ö–∞—Ä—Ç–∏–Ω–∫–∞ (–Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ)"

async def generate_digest_text(messages: list, style: str = 'hardcore', chat_id: int = 0):
    system_prompt = STYLES.get(style, STYLES['hardcore'])
    
    history = "\n".join([
        f"{msg['user']}: {msg['text']} {'[–ö–ê–†–¢–ò–ù–ö–ê: ' + msg['image_desc'] + ']' if msg.get('image_desc') else ''}"
        for msg in messages
    ])
    
    chat_link = str(abs(chat_id)).replace('100', '')
    
    prompt = f"""
{system_prompt}

–®–ê–ë–õ–û–ù –í–´–í–û–î–ê:
üì∞ –ì–ª–∞–≤–Ω–æ–µ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 1000 —Å–æ–æ–±—â–µ–Ω–∏–π, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞ –ø–æ —á–∞—Ç—É:

# (—Å—Å—ã–ª–∫–∞) –¢–µ–∫—Å—Ç...
# (—Å—Å—ã–ª–∫–∞) –¢–µ–∫—Å—Ç...
(–≤—Å–µ–≥–æ 9 –ø—É–Ω–∫—Ç–æ–≤)

–ò–°–¢–û–†–ò–Ø –ß–ê–¢–ê –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{history}

–í–´–ë–ï–†–ò –¢–û–ü-9 –°–ê–ú–´–• –ò–ù–¢–ï–†–ï–°–ù–´–•/–°–ú–ï–®–ù–´–•/–°–ö–ê–ù–î–ê–õ–¨–ù–´–• –ú–û–ú–ï–ù–¢–û–í –ò –û–ü–ò–®–ò –ò–• –í –°–¢–ò–õ–ï –í–´–®–ï.
"""
    
    try:
        response = await client.chat.completions.create(
            model="llama-3.1-8b-instant",  # –ú–æ–¥–µ–ª—å —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –∏ –±–µ—Å–ø–ª–∞—Ç–Ω–∞
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            temperature=0.9,
            max_tokens=4000
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"‚ùå –û—à–∏–±–∫–∞ –ò–ò: {e}"

async def ai_answer(question: str, context: str, style: str):
    system_prompt = STYLES.get(style, STYLES['hardcore'])
    try:
        response = await client.chat.completions.create(
            model="llama-3.1-8b-instant",
            messages=[
                {"role": "system", "content": f"{system_prompt}\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}"},
                {"role": "user", "content": question}
            ],
            temperature=0.9,
            max_tokens=1000
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"–û—à–∏–±–∫–∞: {e}"
